{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{width:100% !important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pow\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "from roaringbitmap import RoaringBitmap, MultiRoaringBitmap\n",
    "\n",
    "\n",
    "class RoundRobinSamplingBitmap:\n",
    "    \"\"\"A bitmap sketch with fixed max size via variable sampling\"\"\"    \n",
    "    \n",
    "    MAX_uint32_t = 0xFFFFFFFF ## TODO find a more pythonic way to assert this\n",
    "    \n",
    "    # TODO to be stict to remove chance of unitialized member vars\n",
    "    # TODO having a version that requires everything we need for the results of intersection, union, etc\n",
    "    # TODO consider dealing with negatives in pruning\n",
    "    def __init__(self, maxSamples):        \n",
    "        self.maxSamples = maxSamples\n",
    "        self.curSampleRate = 1   # the rate is 1/curSampleRate, so if the value is 4, it is 1/4th. start at 1/1\n",
    "        self.rbm = RoaringBitmap()  \n",
    "\n",
    "    def copy(self):\n",
    "        result = RoundRobinSamplingBitmap(maxSamples=self.maxSamples)\n",
    "        \n",
    "        result.rbm = self.rbm.copy()\n",
    "        result.curSampleRate = self.curSampleRate\n",
    "        return result\n",
    "        \n",
    "    def _checkSize(self):          \n",
    "        # first, prune out anything beyond the max because they're not in the sample\n",
    "        self._prune()\n",
    "\n",
    "        # now, as long have more than the maxSamples number, we need to grow our sampling rate and re-prune\n",
    "        while len(self.rbm) > self.maxSamples:\n",
    "            self.curSampleRate *= 2 # TODO consider different sampleRate scaling instead of 2\n",
    "            self._prune()\n",
    "\n",
    "    def _getCurMaxAllowed(self):\n",
    "        return int(self.MAX_uint32_t / self.curSampleRate)\n",
    "    \n",
    "    def _prune(self):          \n",
    "        curMaxAllowed = self._getCurMaxAllowed()\n",
    "        if self.rbm.max() > curMaxAllowed:\n",
    "            self.rbm = self.rbm.clamp(0, curMaxAllowed)\n",
    "\n",
    "    def add(self, i):          \n",
    "        if i < 0: raise RuntimeError(\"cannot yet support negative id values\")      \n",
    "        self.rbm.add(i)\n",
    "        self._checkSize()        \n",
    "        return i\n",
    "    \n",
    "    def _performBitmapOp(self, other, opStr):     \n",
    "                \n",
    "        ## currently need to ensure the instances have the same maxSamples init values\n",
    "        if self.maxSamples != other.maxSamples:\n",
    "            raise RuntimeError(\"you cannot mix instances with different initial maxSamples values\")\n",
    "        ## TODO figure out how to extrapolate, if possible, to allow different init values\n",
    "                     \n",
    "        result = RoundRobinSamplingBitmap(maxSamples=self.maxSamples)\n",
    "               \n",
    "        result.rbm = getattr(self.rbm, opStr)(other.rbm)\n",
    "        result.curSampleRate = max(self.curSampleRate, other.curSampleRate)\n",
    "        \n",
    "        result._checkSize()\n",
    "        return result\n",
    "\n",
    "    \n",
    "    ## the following should work logically but havent really been tested with real data much\n",
    "    def intersection(self, other):        \n",
    "        return self._performBitmapOp(other, \"intersection\")\n",
    "\n",
    "    def union(self, other):        \n",
    "        return self._performBitmapOp(other, \"union\")\n",
    "                 \n",
    "    def difference(self, other):        \n",
    "        return self._performBitmapOp(other, \"difference\")\n",
    "    ## the above should work logically but havent really been tested with real data much\n",
    "\n",
    "    \n",
    "    def estimatedCardinality(self):\n",
    "        return len(self.rbm)*self.curSampleRate\n",
    "        \n",
    "    def _getCurMaxAllowed(self):\n",
    "        return int(self.MAX_uint32_t / self.curSampleRate)\n",
    "    \n",
    "    ## TODO deprecate this in favor of json dumps\n",
    "    def dumps(self):\n",
    "        state = {\n",
    "            \"estCard\" : int(self.estimatedCardinality()),\n",
    "            \"curSampleRate\" : self.curSampleRate,\n",
    "            \"curMax\" : self.rbm.max(),                        \n",
    "            \"getCurMaxAllowed\" : self._getCurMaxAllowed(),                        \n",
    "        }        \n",
    "        return json.dumps(state)\n",
    "    \n",
    "    def errPct(self, target):\n",
    "        precision = 3\n",
    "        mult = pow(10,precision+1)\n",
    "        return int(mult*(self.estimatedCardinality()-target)/target)/mult\n",
    "                \n",
    "\n",
    "print(RoundRobinSamplingBitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "random.seed(time.time()*1000)\n",
    "\n",
    "\n",
    "## this cell creates a rbmrr or increasing size and saves off snapshot copies along the way.\n",
    "## also, for each addition it increments a count for the observed value of error between the \n",
    "## actual and estimated cardinality.\n",
    "\n",
    "rbmrr = RoundRobinSamplingBitmap(maxSamples=1000)\n",
    "\n",
    "iterations = 1000*1000 #100*1000*1000\n",
    "\n",
    "snapshots = {}\n",
    "NUM_SNAPSHOTS = 50\n",
    "errHistogram = defaultdict(lambda:0)\n",
    "\n",
    "for i in range(1,iterations+1):\n",
    "        \n",
    "    rbmrr.add(random.randint(0,rbmrr.MAX_uint32_t))\n",
    "    errHistogram[rbmrr.errPct(i)] += 1\n",
    "    \n",
    "    if (NUM_SNAPSHOTS > 0 and i % (iterations/NUM_SNAPSHOTS) == 0): \n",
    "        print(i, rbmrr.errPct(i), rbmrr.dumps())\n",
    "        snapshots[i] = rbmrr.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this cell walks the errHistogram twice to compute percentiles on observed estimation error\n",
    "\n",
    "\n",
    "## the first traversal is to increment a total count and to compute a new dictory keyed \n",
    "## on the abs value of observed differences between the actual and estimated cardinality.\n",
    "## it also sums the counts overall so we have the total amount.\n",
    "\n",
    "absHist, totalCount = {}, 0\n",
    "for errPct, count in errHistogram.items():\n",
    "    totalCount += count\n",
    "    if abs(errPct) not in absHist:\n",
    "        absHist[abs(errPct)] =0\n",
    "\n",
    "    absHist[abs(errPct)] += count\n",
    "    \n",
    "##  the second time walks the abs of the error to show cumulative counts.\n",
    "    \n",
    "cumulativeCount = 0\n",
    "for absErrPct, count in sorted(absHist.items()):\n",
    "    cumulativeCount += count\n",
    "    print(absErrPct, count, cumulativeCount/totalCount)\n",
    "    \n",
    "    \n",
    "## with a recent run, for example, the max error was 3.88%. that is, for all keys \n",
    "## values added sequentially from 1 and 100,000,000 using at most 10,000 samples,\n",
    "## the max error was 3.88% and that occured only 488 times. the p95 of error for the\n",
    "## same keys was 3.49%\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## here we use the snapshots to compare error in intersect estimates\n",
    "\n",
    "largestSnapshotSize = max(snapshots.keys())\n",
    "largestSnapshot = snapshots[largestSnapshotSize]\n",
    "\n",
    "print(\"intersecting with the largest snapshot with %d entries\\n\" % largestSnapshotSize)\n",
    "\n",
    "intersectErrPcts = []\n",
    "for k,v in snapshots.items():\n",
    "    intersect = largestSnapshot.intersection(v)\n",
    "    intersectErrPcts.append(intersect.errPct(k))\n",
    "    print(k, intersect.errPct(k), intersect.dumps())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrb = MultiRoaringBitmap([v.rbm.freeze() for v in snapshots.values()])\n",
    "print(\"avg snapshot size: %d bytes\" % (mrb.bufsize()/len(snapshots.values())))\n",
    "\n",
    "snapshotBufsize = [(k,v.curSampleRate,MultiRoaringBitmap([v.rbm]).bufsize()) for (k,v) in snapshots.items()]\n",
    "sorted(snapshotBufsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
