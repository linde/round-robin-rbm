{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{width:100% !important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pow\n",
    "import random\n",
    "import json\n",
    "\n",
    "from roaringbitmap import RoaringBitmap, MultiRoaringBitmap\n",
    "\n",
    "class RoundRobinSamplingBitmap:\n",
    "    \"\"\"A bitmap sketch with fixed max size via variable sampling\"\"\"    \n",
    "    \n",
    "    MAX_uint32_t = 0xFFFFFFFF ## TODO find a more pythonic way to assert this. this is hard in python3\n",
    "    \n",
    "    # TODO to be stict to remove chance of unitialized member vars\n",
    "    # TODO having a version that requires everything we need for the results of intersection, union, etc\n",
    "    # TODO consider dealing with negatives in pruning\n",
    "    def __init__(self, maxSamples, initMaxAllowed=MAX_uint32_t):        \n",
    "        self.maxSamples = maxSamples\n",
    "        self.initMaxAllowed = initMaxAllowed\n",
    "        \n",
    "        self.rbm = RoaringBitmap()  \n",
    "        self.curMaxAllowed = initMaxAllowed\n",
    "\n",
    "    def copy(self):\n",
    "        result = RoundRobinSamplingBitmap(maxSamples=self.maxSamples, initMaxAllowed=self.initMaxAllowed)\n",
    "        \n",
    "        result.rbm = self.rbm.copy()\n",
    "        result.curMaxAllowed = self.curMaxAllowed\n",
    "        return result\n",
    "        \n",
    "    def _checkSize(self):          \n",
    "        # first, prune out anything beyond the max because they're not in the sample\n",
    "        self._prune()\n",
    "\n",
    "        # now, as long have more than the maxSamples number, we need to shrink our curMaxAllowed value and re-prune\n",
    "        while len(self.rbm) > self.maxSamples:\n",
    "            self.curMaxAllowed = int(self.curMaxAllowed/2)   # TODO consider shrinking by something other than half\n",
    "            self._prune()\n",
    "\n",
    "    def _prune(self):          \n",
    "        ## TODO before bother to clamp, check if needed\n",
    "        self.rbm = self.rbm.clamp(0, self.curMaxAllowed)\n",
    "\n",
    "    def add(self, i):  \n",
    "        \n",
    "        if i < 0:\n",
    "            raise \n",
    "        \n",
    "        self.rbm.add(i)\n",
    "        self._checkSize()        \n",
    "        return i\n",
    "    \n",
    "    def intersection(self, other):        \n",
    "        ## we need to ensure the instances have the same init values\n",
    "        ## TODO verify that we can't relax this for either value somehow\n",
    "        \n",
    "        if self.maxSamples != other.maxSamples or self.initMaxAllowed != other.initMaxAllowed:\n",
    "            raise RuntimeError(\"you cannot mix instances with different initial values\")\n",
    "\n",
    "        result = RoundRobinSamplingBitmap(maxSamples=self.maxSamples, initMaxAllowed=self.initMaxAllowed)\n",
    "        result.rbm = self.rbm.intersection(other.rbm)\n",
    "        result.curMaxAllowed = min(self.curMaxAllowed, other.curMaxAllowed)\n",
    "        \n",
    "        result._checkSize()\n",
    "        return result\n",
    "    \n",
    "    def union(self, other):        \n",
    "        ## we need to ensure the instances have the same init values\n",
    "        ## TODO verify that we can't relax this for either value somehow\n",
    "        \n",
    "        if self.maxSamples != other.maxSamples or self.initMaxAllowed != other.initMaxAllowed:\n",
    "            raise RuntimeError(\"you cannot mix instances with different initial values\")\n",
    "\n",
    "        result = RoundRobinSamplingBitmap(maxSamples=self.maxSamples, initMaxAllowed=self.initMaxAllowed)\n",
    "        result.rbm = self.rbm.union(other.rbm)\n",
    "        result.curMaxAllowed = min(self.curMaxAllowed, other.curMaxAllowed)\n",
    "        \n",
    "        result._checkSize()\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    ### TODO implement NOT for the set\n",
    "                 \n",
    "    def estimatedCardinality(self):\n",
    "        return len(self.rbm)*(self.initMaxAllowed/self.curMaxAllowed)\n",
    "    \n",
    "    def curMax(self):\n",
    "        return self.rbm.max()\n",
    "    \n",
    "    \n",
    "    ## TODO deprecate this in favor of json dumps\n",
    "    def dumps(self):\n",
    "        state = {\n",
    "            \"estCard\" : int(self.estimatedCardinality()),\n",
    "            \"curMax\" : self.curMax(),                        \n",
    "            \"curMaxAllowed\" : self.curMaxAllowed,    \n",
    "            \"initMaxAllowed\" : self.initMaxAllowed\n",
    "        }        \n",
    "        return json.dumps(state)\n",
    "    \n",
    "    def errPct(self, target):\n",
    "        precision = 3\n",
    "        mult = pow(10,precision+1)\n",
    "        return int(mult*(self.estimatedCardinality()-target)/target)/mult\n",
    "        \n",
    "\n",
    "print(RoundRobinSamplingBitmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "random.seed(time.time()*1000)\n",
    "\n",
    "\n",
    "## this cell creates a rbmrr or increasing size and saves off snapshot copies along the way.\n",
    "## also, for each addition it increments a count for the observed value of error between the \n",
    "## actual and estimated cardinality.\n",
    "\n",
    "rbmrr = RoundRobinSamplingBitmap(maxSamples=10*1000)\n",
    "\n",
    "getRandomInRange = lambda: random.randint(0,rbmrr.initMaxAllowed)  \n",
    "iterations = 100*1000\n",
    "\n",
    "snapshots = {}\n",
    "NUM_SNAPSHOTS = 200\n",
    "errHistogram = {} # TODO consider using defaultdict\n",
    "\n",
    "for i in range(1,iterations+1):\n",
    "    \n",
    "    # if i % (iterations/1000) == 0: print(\"processing %d\" % i)\n",
    "        \n",
    "    rbmrr.add(getRandomInRange())\n",
    "    \n",
    "    errPct = rbmrr.errPct(i)\n",
    "    if errPct not in errHistogram:\n",
    "        errHistogram[errPct] = 1\n",
    "    else:\n",
    "        errHistogram[errPct] += 1\n",
    "            \n",
    "    if (NUM_SNAPSHOTS > 0 and i % (iterations/NUM_SNAPSHOTS) == 0): \n",
    "        print(i, rbmrr.errPct(i), rbmrr.dumps())\n",
    "        snapshots[i] = rbmrr.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this cell walks the errHistogram twice to compute percentiles on observed estimation error\n",
    "\n",
    "\n",
    "## the first traversal is to increment a total count and to compute a new dictory keyed \n",
    "## on the abs value of observed differences between the actual and estimated cardinality.\n",
    "## it also sums the counts overall so we have the total amount.\n",
    "\n",
    "absHist, totalCount = {}, 0\n",
    "for errPct, count in errHistogram.items():\n",
    "    totalCount += count\n",
    "    if abs(errPct) not in absHist:\n",
    "        absHist[abs(errPct)] =0\n",
    "\n",
    "    absHist[abs(errPct)] += count\n",
    "    \n",
    "##  the second time walks the abs of the error to show cumulative counts.\n",
    "    \n",
    "cumulativeCount = 0\n",
    "for absErrPct, count in sorted(absHist.items()):\n",
    "    cumulativeCount += count\n",
    "    print(absErrPct, count, cumulativeCount/totalCount)\n",
    "    \n",
    "    \n",
    "## with a recent run, for example, the max error was 3.88%. that is, for all keys \n",
    "## values added sequentially from 1 and 100,000,000 using at most 10,000 samples,\n",
    "## the max error was 3.88% and that occured only 488 times. the p95 of error for the\n",
    "## same keys was 3.49%\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## here we use the snapshots to compare error in intersect estimates\n",
    "\n",
    "largestSnapshotSize = max(snapshots.keys())\n",
    "largestSnapshot = snapshots[largestSnapshotSize]\n",
    "\n",
    "print(\"intersecting with the largest snapshot with %d entries\\n\" % largestSnapshotSize)\n",
    "\n",
    "intersectErrPcts = []\n",
    "for k,v in snapshots.items():\n",
    "    intersect = largestSnapshot.intersection(v)\n",
    "    intersectErrPcts.append(intersect.errPct(k))\n",
    "    print(k, intersect.errPct(k), intersect.dumps())\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
